{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pylab as plt\nimport glob\nimport os\nimport random\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras import metrics\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.models import Sequential, Model\nfrom keras.utils import plot_model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport cv2\nfrom tqdm import tqdm\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nimport sklearn\nfrom collections import Counter\nfrom pandas import DataFrame\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data_local(new_w,new_h):\n    train_labels = pd.read_csv(r'C:\\Users\\aleja\\OneDrive\\Desktop\\Kaggle\\Leave Issues Competition\\train.csv',sep=',')\n    path_loop = r\"C:\\Users\\aleja\\OneDrive\\Desktop\\Kaggle\\Leave Issues Competition\\train_images\\*.*\"\n    path = r\"C:\\Users\\aleja\\OneDrive\\Desktop\\Kaggle\\Leave Issues Competition\\train_images\"\n    onlyfiles = next(os.walk(path))[2] #dir is your directory path as string\n    numOfFiles = len(onlyfiles)\n    data = []\n    for file in tqdm(glob.glob(path_loop)):\n        a=cv2.imread(file)\n        name_file = os.path.basename(file)\n        label = train_labels.loc[train_labels['image_id'] == name_file,'label'].values\n        #conversion numpy array into rgb image to show\n        c = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n        h, w, channels = c.shape\n        #input size of Resnet architecture\n        frame_rgb = cv2.resize(c,(new_w,new_h),interpolation=cv2.INTER_CUBIC)\n        data.append([frame_rgb,label])\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(new_w,new_h):\n    train_labels = pd.read_csv('../input/cassava-leaf-disease-classification/train.csv', sep=',')\n    path = '../input/cassava-leaf-disease-classification/train_images'\n    path_loop = r'../input/cassava-leaf-disease-classification/train_images/*.*'\n    onlyfiles = next(os.walk(path))[2] #dir is your directory path as string\n    numOfFiles = len(onlyfiles)\n    data = []\n    for file in tqdm(glob.glob(path_loop)):\n        a=cv2.imread(file)\n        name_file = os.path.basename(file)\n        label = train_labels.loc[train_labels['image_id'] == name_file,'label'].values\n        #conversion numpy array into rgb image to show\n        c = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n        h, w, channels = c.shape\n        #input size of Resnet architecture\n        frame_rgb = cv2.resize(c,(new_w,new_h),interpolation=cv2.INTER_CUBIC)\n        data.append([frame_rgb,label])\n    return data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Change before submitting to Kaggle from load_data_local to load_data\nIMG_SIZE_X = 128\nIMG_SIZE_Y = 128\ndata = load_data(IMG_SIZE_X, IMG_SIZE_Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_test_split_modified(data):\n    x_data = []\n    y_data = []\n    \n    for feature, label in data:\n        x_data.append(feature)\n        y_data.append(label)\n        \n    X_data, X_test, Y_data, Y_test = sklearn.model_selection.train_test_split(x_data, y_data, stratify = y_data, test_size=0.1, random_state=42)\n    X_model_1, X_aux, Y_model_1, Y_aux = sklearn.model_selection.train_test_split(X_data, Y_data, stratify = Y_data, test_size=0.66, random_state=42)\n    X_model_2, X_model_3, Y_model_2, Y_model_3 = sklearn.model_selection.train_test_split(X_aux, Y_aux, stratify = Y_aux, test_size=0.5, random_state=42)\n    return X_test, Y_test, X_model_1, Y_model_1, X_model_2, Y_model_2, X_model_3, Y_model_3\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data_preparation(X_data, Y_data, new_h, new_w, channels):\n    x_train,x_val,y_train,y_val = train_test_split(X_data,Y_data,stratify=Y_data, train_size=0.8, random_state=42)\n    x_train = np.array(x_train) / 255\n    x_val = np.array(x_val) / 255\n    y_train = np.array(y_train)\n    y_val = np.array(y_val)\n    x_train = x_train.reshape(-1, new_h, new_w, channels)\n    x_val = x_val.reshape(-1, new_h, new_w, channels)\n\n    return x_train, x_val, y_train, y_val","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encode target variables\ndef encode_target_variable(y_train,y_val):\n    onehot_encoder = OneHotEncoder(sparse=False)\n    y_train = y_train.reshape(-1,1)\n    y_val = y_val.reshape(-1,1)\n    y_train_onehot = onehot_encoder.fit_transform(y_train)\n    y_val_onehot = onehot_encoder.fit_transform(y_val)\n    return y_train_onehot, y_val_onehot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_1(x_train,x_val):\n    resnet50 = ResNet50(weights='../input/weights-climbers/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(IMG_SIZE_X, IMG_SIZE_Y, 3))\n    resnet50.trainable = False # remove if you want to retrain resnet weights\n    # resnet50.summary()\n    transfer_model_1 = Sequential()\n    transfer_model_1.add(resnet50)\n    transfer_model_1.add(Flatten())\n    transfer_model_1.add(Dense(128, activation='relu'))\n    transfer_model_1.add(Dropout(0.2))\n    transfer_model_1.add(Dense(5, activation='softmax'))\n    transfer_model_1.summary()\n    x_train_new = x_train\n    x_val_new = x_val\n    x_train_new = keras.applications.resnet50.preprocess_input(x_train_new)\n    x_val_new = keras.applications.resnet50.preprocess_input(x_val_new)\n    return transfer_model_1, x_train_new, x_val_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_2(x_train,x_val):\n    vgg16 = VGG16(weights='../input/weights-climbers/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(IMG_SIZE_X, IMG_SIZE_Y, 3))\n    vgg16.trainable = False # remove if you want to retrain vgg16 weights\n    # vgg16.summary()\n    transfer_model_2 = Sequential()\n    transfer_model_2.add(vgg16)\n    transfer_model_2.add(Flatten())\n    transfer_model_2.add(Dense(128, activation='relu'))\n    transfer_model_2.add(Dropout(0.2))\n    transfer_model_2.add(Dense(5, activation='softmax'))\n    transfer_model_2.summary()\n    x_train_new = x_train\n    x_val_new = x_val\n    x_train_new = keras.applications.vgg16.preprocess_input(x_train_new)\n    x_val_new = keras.applications.vgg16.preprocess_input(x_val_new)\n    return transfer_model_2, x_train_new, x_val_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_3(x_train,x_val):\n    inceptionV3 = InceptionV3(weights='../input/weights-climbers/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', include_top=False, input_shape=(IMG_SIZE_X, IMG_SIZE_Y, 3))\n    inceptionV3.trainable = False # remove if you want to retrain rinceptionV3 weights\n    # inceptionV3.summary()\n    transfer_model_3 = Sequential()\n    transfer_model_3.add(inceptionV3)\n    transfer_model_3.add(Flatten())\n    transfer_model_3.add(Dense(128, activation='relu'))\n    transfer_model_3.add(Dropout(0.2))\n    transfer_model_3.add(Dense(5, activation='softmax'))\n    transfer_model_3.summary()\n    x_train_new = x_train\n    x_val_new = x_val\n    x_train_new = keras.applications.inception_v3.preprocess_input(x_train_new)\n    x_val_new = keras.applications.inception_v3.preprocess_input(x_val_new)\n    return transfer_model_3, x_train_new, x_val_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot):\n    \n    batch_size = batch_size\n    epochs = epochs\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n              metrics=['categorical_accuracy',keras.metrics.AUC(),keras.metrics.Recall()])\n\n    history = model.fit(x_train_new, y_train_onehot, \\\n                              batch_size=batch_size, epochs=epochs, \\\n                              validation_split=0.2, verbose=1, shuffle=True, validation_data=(x_val_new, y_val_onehot))\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################## Main function ######################\n\n\nnew_h = IMG_SIZE_X\nnew_w = IMG_SIZE_Y\nbatch_size = 200\nepochs = 15\nchannels = 3\n#Divide data into test and training/validation for three different models\nX_test, Y_test, X_model_1, Y_model_1, X_model_2, Y_model_2, X_model_3, Y_model_3 = train_test_split_modified(data)\ntraining_data = [X_model_1, Y_model_1, X_model_2, Y_model_2, X_model_3, Y_model_3]\n#Check that the training datasets are correctly stratified \nY_model_1_df = DataFrame(Y_model_1,columns=['labels'])\n#print(Y_model_1_df.labels.value_counts())\nY_model_2_df = DataFrame(Y_model_2,columns=['labels'])\n#print(Y_model_2_df.labels.value_counts())\nY_model_3_df = DataFrame(Y_model_3,columns=['labels'])\n#print(Y_model_3_df.labels.value_counts())\n#deaseases explanation: {\"0\": \"Cassava Bacterial Blight (CBB)\", \n#\"1\": \"Cassava Brown Streak Disease (CBSD)\", \"2\": \"Cassava Green Mottle (CGM)\", \n#\"3\": \"Cassava Mosaic Disease (CMD)\", \"4\": \"Healthy\"}\n\n#visualize each of the classes\nfig = plt.figure(figsize=(10, 6))\n\nfor i in range(8):\n    img = X_model_1[i]\n    fig.add_subplot(2, 4, i+1)\n    plt.imshow(img)\n    plt.title(Y_model_1[i])\n#Resnet50\nx_train, x_val, y_train, y_val = data_preparation(training_data[0], training_data[1], new_h, new_w, channels)\ny_train_onehot, y_val_onehot = encode_target_variable(y_train,y_val)\ndel y_train, y_val\nresnet50_model, x_train_new, x_val_new = create_model_1(x_train,x_val)\ndel x_train,x_val\ngc.collect()\nresnet50_model = train_model(resnet50_model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot)\n#vgg16\nx_train, x_val, y_train, y_val = data_preparation(training_data[2], training_data[3], new_h, new_w, channels)\ny_train_onehot, y_val_onehot = encode_target_variable(y_train,y_val)\nvgg16_model, x_train_new, x_val_new = create_model_2(x_train,x_val)\ngc.collect()\nvgg16_model = train_model(vgg16_model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot)\n#InceptionV3\nx_train, x_val, y_train, y_val = data_preparation(training_data[4], training_data[5], new_h, new_w, channels)\ny_train_onehot, y_val_onehot = encode_target_variable(y_train,y_val)\ninception_model, x_train_new, x_val_new = create_model_3(x_train,x_val)\ngc.collect()\ninception_model = train_model(inception_model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_test_data(new_w,new_h):\n    path = '../input/cassava-leaf-disease-classification/test_images'\n    path_loop = r'../input/cassava-leaf-disease-classification/test_images/*.*'\n    onlyfiles = next(os.walk(path))[2] #dir is your directory path as string\n    numOfFiles = len(onlyfiles)\n    data = []\n    name_files = []\n    for file in tqdm(glob.glob(path_loop)):\n        a=cv2.imread(file)\n        name_file = os.path.basename(file)\n        #conversion numpy array into rgb image to show\n        c = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n        h, w, channels = c.shape\n        #input size of Resnet architecture\n        frame_rgb = cv2.resize(c,(new_w,new_h),interpolation=cv2.INTER_CUBIC)\n        x_train = np.array(frame_rgb) / 255\n        x_train = x_train.reshape(-1, new_h, new_w, channels)\n        data.append([x_train])\n        name_files.append(name_file)\n    return data, name_files","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create the CSV\ndata, name_files = load_test_data(IMG_SIZE_X,IMG_SIZE_Y)\npredictions = inception_model.predict(data)\npred_df = pd.DataFrame(predictions)\npred_list = pred_df.idxmax(axis=\"columns\")\npred_df = pd.DataFrame(zip(name_files, pred_list), columns = [\"image_id\", \"label\"])\npred_df.head()\npd.DataFrame(pred_df, columns=['predictions']).to_csv('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}