{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pylab as plt\nimport glob\nimport os\nimport random\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras import metrics\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.models import Sequential, Model\nfrom keras.utils import plot_model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport cv2\nfrom tqdm import tqdm\nfrom keras.callbacks import EarlyStopping\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nimport sklearn\nfrom collections import Counter\nfrom pandas import DataFrame\nimport gc\nimport tensorflow as tf\nfrom sklearn.utils import class_weight\nfrom sklearn.utils.class_weight import compute_class_weight","execution_count":78,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv_path = \"../input/cassava-leaf-disease-classification/train.csv\"\nlabel_json_path = \"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\"\nimages_dir_path = \"../input/cassava-leaf-disease-classification/train_images\"\ntest_csv_path = \"../input/cassava-leaf-disease-classification/sample_submission.csv\"\ntrain_csv['label'] = train_csv['label'].astype('string')\n\nx_train, x_val, y_train, y_val = train_test_split(train_csv['image_id'], train_csv['label'], test_size = 0.1, random_state = 27, stratify=train_csv['label'])\ny_train_onehot, y_val_onehot, d_class_weights = encode_target_variable(y_train,y_val)\n#train df\ndf_train = pd.DataFrame(columns=['image_id','label'])\ndf_train['image_id'] = x_train\ndf_train['label'] = y_train\n\n#validation df\ndf_val = pd.DataFrame(columns=['image_id','label'])\ndf_val['image_id'] = x_val\ndf_val['label'] = y_val\n\ndf_train.reset_index(drop=True, inplace=True)\ndf_val.reset_index(drop=True, inplace=True)\n\nlabel_class = pd.read_json(label_json_path, orient='index')\nlabel_class = label_class.values.flatten().tolist()\nIMG_SIZE = 512\nBATCH_SIZE = 24\nEPOCHS = 15\nCHANNELS = 3","execution_count":79,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=['0' '1' '2' '3' '4'], y=8644     3\n18281    0\n14735    0\n3906     1\n11276    3\n        ..\n1570     1\n20304    3\n16067    1\n18894    2\n13547    3\nName: label, Length: 19257, dtype: string as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Label names :\")\nfor i, label in enumerate(label_class):\n    print(f\" {i}. {label}\")","execution_count":51,"outputs":[{"output_type":"stream","text":"Label names :\n 0. Cassava Bacterial Blight (CBB)\n 1. Cassava Brown Streak Disease (CBSD)\n 2. Cassava Green Mottle (CGM)\n 3. Cassava Mosaic Disease (CMD)\n 4. Healthy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = ImageDataGenerator(\n                                rotation_range=270,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                brightness_range=[0.1,0.9],\n                                shear_range=25,\n                                zoom_range=0.3,\n                                channel_shift_range=0.1,\n                                horizontal_flip=True,\n                                vertical_flip=True,\n                                rescale=1/255,\n                                validation_split=0.2\n                               )\n                                    \n    \nvalid_gen = ImageDataGenerator(rescale=1/255,\n                               validation_split = 0.2\n                              )\n\ntest_gen=ImageDataGenerator(rescale=1./255.)","execution_count":93,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_gen.flow_from_dataframe(\n                            dataframe=df_train,\n                            directory = images_dir_path,\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            class_mode = \"categorical\",\n                            batch_size = BATCH_SIZE,\n                            shuffle = True,\n                            subset = \"training\"\n\n)\n\nvalid_generator = valid_gen.flow_from_dataframe(\n                            dataframe=df_val,\n                            directory = images_dir_path,\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            class_mode = \"categorical\",\n                            batch_size = BATCH_SIZE,\n                            shuffle = False,\n                            subset = \"validation\"\n)\n\npredict_generator = test_gen.flow_from_dataframe(\n                            dataframe=df_val,\n                            directory = images_dir_path,\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            class_mode = None,\n                            batch_size = BATCH_SIZE,\n                            shuffle = False)","execution_count":95,"outputs":[{"output_type":"stream","text":"Found 15406 validated image filenames belonging to 5 classes.\nFound 428 validated image filenames belonging to 5 classes.\nFound 2140 validated image filenames.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encode target variables\ndef encode_target_variable(y_train,y_val):\n\n    class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n    d_class_weights = dict(enumerate(class_weights))\n    onehot_encoder = OneHotEncoder(sparse=False)\n    y_train = np.array(y_train)\n    y_val = np.array(y_val)\n    y_train = y_train.reshape(-1,1)\n    y_val = y_val.reshape(-1,1)\n    y_train_onehot = onehot_encoder.fit_transform(y_train)\n    y_val_onehot = onehot_encoder.fit_transform(y_val)\n    return y_train_onehot, y_val_onehot, d_class_weights","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_0(input_shape):\n    input_img = Input(shape=input_shape)  \n    x = Conv2D(16, (5, 5), activation='relu', padding='same')(input_img)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(16, (5, 5), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(16, (5, 5), activation='relu', padding='same')(x)\n    x = Dropout(0.3)(x)\n    y = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n    y = MaxPooling2D((2, 2), padding='same')(y)\n    y = Conv2D(16, (3, 3), activation='relu', padding='same')(y)\n    y = MaxPooling2D((2, 2), padding='same')(y)\n    y = Conv2D(16, (3, 3), activation='relu', padding='same')(y)\n    y = Dropout(0.4)(y)\n    z = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n    z = MaxPooling2D((2, 2), padding='same')(z)\n    z = Conv2D(16, (3, 3), activation='relu', padding='same')(z)\n    z = MaxPooling2D((2, 2), padding='same')(z)\n    z = Conv2D(16, (3, 3), activation='relu', padding='same')(z)\n\n    #out = layers.concatenate([x, y, z])\n    out = layers.Flatten()(z)\n    out = Dense(16, activation='relu')(out)\n    out = Dense(5, activation='softmax')(out)\n    \n    model_f = Model(inputs=[input_img], outputs=[out])\n    model_f.summary()\n    return model_f","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_1(input_shape):\n    weights_path = '../input/weightsclimbers/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    resnet50 = ResNet50(weights = None ,include_top=False, input_shape=input_shape)\n    resnet50.load_weights(weights_path, by_name=True)\n    resnet50.trainable = False # remove if you want to retrain resnet weights\n    # resnet50.summary()\n    transfer_model_1 = Sequential() \n    transfer_model_1.add(resnet50)\n    transfer_model_1.add(Flatten())\n    transfer_model_1.add(Dense(128, activation='relu'))\n    transfer_model_1.add(Dropout(0.2))\n    transfer_model_1.add(Dense(5, activation='softmax'))\n    transfer_model_1.summary()\n    return transfer_model_1","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_2(x_train,x_val):\n    weights_path = '../input/weightsclimbers/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    vgg16 = VGG16(weights=None, include_top=False, input_shape=(IMG_SIZE_X, IMG_SIZE_Y, 3))\n    vgg16.load_weights(weights_path, by_name=True)\n    vgg16.trainable = False # remove if you want to retrain vgg16 weights\n    # vgg16.summary()\n    transfer_model_2 = Sequential()\n    transfer_model_2.add(vgg16)\n    transfer_model_2.add(Flatten())\n    transfer_model_2.add(Dense(128, activation='relu'))\n    transfer_model_2.add(Dropout(0.2))\n    transfer_model_2.add(Dense(5, activation='softmax'))\n    transfer_model_2.summary()\n    x_train_new = x_train\n    x_val_new = x_val\n    x_train_new = keras.applications.vgg16.preprocess_input(x_train_new)\n    x_val_new = keras.applications.vgg16.preprocess_input(x_val_new)\n    return transfer_model_2, x_train_new, x_val_new","execution_count":85,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_3(x_train,x_val):\n    weights_path = '../input/weightsclimbers/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    inceptionV3 = InceptionV3(weights=None, include_top=False, input_shape=(IMG_SIZE_X, IMG_SIZE_Y, 3))\n    inceptionV3.load_weights(weights_path, by_name=False)\n    inceptionV3.trainable = False # remove if you want to retrain rinceptionV3 weights\n    # inceptionV3.summary()\n    transfer_model_3 = Sequential()\n    transfer_model_3.add(inceptionV3)\n    transfer_model_3.add(Flatten())\n    transfer_model_3.add(Dense(128, activation='relu'))\n    transfer_model_3.add(Dropout(0.2))\n    transfer_model_3.add(Dense(5, activation='softmax'))\n    transfer_model_3.summary()\n    x_train_new = x_train\n    x_val_new = x_val\n    x_train_new = keras.applications.inception_v3.preprocess_input(x_train_new)\n    x_val_new = keras.applications.inception_v3.preprocess_input(x_val_new)\n    return transfer_model_3, x_train_new, x_val_new","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, batch_size, epochs, weights):\n    \n    batch_size = batch_size\n    epochs = epochs\n    \n    def scheduler(epoch, lr):\n        if epoch >3 and epoch%2==0:\n            return lr/1.25\n        else:\n            return lr\n    \n    callback_learning_rate = tf.keras.callbacks.LearningRateScheduler(scheduler)\n    \n    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), \n              metrics=['categorical_accuracy',keras.metrics.AUC(),keras.metrics.Recall()])\n    \n    earlyStop_callback = tf.keras.callbacks.EarlyStopping(monitor='categorical_accuracy', \n                                                          patience=2,restore_best_weights = True, min_delta = 0.01)\n    \n    \n    \n    model.fit_generator(train_generator, \n                    epochs=epochs,  # one forward/backward pass of training data\n                    steps_per_epoch=25,  # number of images comprising of one epoch\n                    validation_data=valid_generator, # Or validation_data=valid_generator\n                    validation_steps=valid_generator.samples//valid_generator.batch_size,\n                    callbacks = [earlyStop_callback, callback_learning_rate],\n                       class_weight = {0:1,1:1,2:1,3:0.1,4:1})\n    return model","execution_count":115,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################## Main function ######################\n\n    \n#Baseline model\n\ninput_shape = [IMG_SIZE,IMG_SIZE,CHANNELS]\n# baseline_model = create_model_0(input_shape)\n# baseline_model = train_model(baseline_model, BATCH_SIZE, EPOCHS)\ny_train_onehot, y_val_onehot, class_weights = encode_target_variable(y_train,y_val)\n\n# #Resnet50\nRESNET_model = create_model_1(input_shape)\nRESNET_model = train_model(RESNET_model, BATCH_SIZE, EPOCHS, class_weights)\n# #vgg16\n# x_train, x_val, y_train, y_val = data_preparation(training_data[2], training_data[3], new_h, new_w, channels)\n# y_train_onehot, y_val_onehot, class_weights = encode_target_variable(y_train,y_val)\n# del y_train, y_val\n# vgg16_model, x_train_new, x_val_new = create_model_2(x_train,x_val)\n# del x_train,x_val\n# gc.collect()\n# vgg16_model = train_model(vgg16_model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot, class_weights)\n# #InceptionV3\n# x_train, x_val, y_train, y_val = data_preparation(training_data[4], training_data[5], new_h,new_w, channels)\n# y_train_onehot, y_val_onehot, class_weights = encode_target_variable(y_train,y_val)\n# del y_train, y_val\n# inception_model, x_train_new, x_val_new = create_model_3(x_train,x_val)\n# del x_train,x_val\n# gc.collect()\n# inception_model = train_model(inception_model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot, class_weights)","execution_count":116,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=['0' '1' '2' '3' '4'], y=8644     3\n18281    0\n14735    0\n3906     1\n11276    3\n        ..\n1570     1\n20304    3\n16067    1\n18894    2\n13547    3\nName: label, Length: 19257, dtype: string as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n","name":"stderr"},{"output_type":"stream","text":"Model: \"sequential_10\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Functional)        (None, 16, 16, 2048)      23587712  \n_________________________________________________________________\nflatten_10 (Flatten)         (None, 524288)            0         \n_________________________________________________________________\ndense_20 (Dense)             (None, 128)               67108992  \n_________________________________________________________________\ndropout_10 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_21 (Dense)             (None, 5)                 645       \n=================================================================\nTotal params: 90,697,349\nTrainable params: 67,109,637\nNon-trainable params: 23,587,712\n_________________________________________________________________\n","name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"'list' object has no attribute 'keys'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-116-aee26b0a205f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# #Resnet50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mRESNET_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mRESNET_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRESNET_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# #vgg16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# x_train, x_val, y_train, y_val = data_preparation(training_data[2], training_data[3], new_h, new_w, channels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-115-e8e32b9c6838>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, batch_size, epochs, weights)\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mearlyStop_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_learning_rate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                        class_weight = [1,1,1,0.1,1])\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m       \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_make_class_weight_map_fn\u001b[0;34m(class_weight)\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0mweighting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m   \"\"\"\n\u001b[0;32m-> 1295\u001b[0;31m   \u001b[0mclass_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m   \u001b[0mexpected_class_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mclass_ids\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_class_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.models.save_model(RESNET_model,'../output')","execution_count":112,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"RESNET_model = keras.models.load_model('../output')","execution_count":113,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nY_pred = RESNET_model.predict_generator(predict_generator, steps = predict_generator.samples//predict_generator.batch_size+1)\ny_pred = np.argmax(Y_pred, axis=1)\nprint('Confusion Matrix')\nprint(confusion_matrix(df_val['label'].astype('int'), y_pred))\nprint('Classification Report')\ntarget_names = [' 0. Cassava Bacterial Blight (CBB)', ' 1. Cassava Brown Streak Disease (CBSD)', ' 2. Cassava Green Mottle (CGM)',' 3. Cassava Mosaic Disease (CMD)','4. Healthy']\nprint(classification_report(df_val['label'].astype('int'), y_pred, target_names=target_names))","execution_count":114,"outputs":[{"output_type":"stream","text":"Confusion Matrix\n[[   0    0    0  109    0]\n [   0    0    0  219    0]\n [   0    0    0  238    0]\n [   0    0    0 1316    0]\n [   0    0    0  258    0]]\nClassification Report\n                                         precision    recall  f1-score   support\n\n      0. Cassava Bacterial Blight (CBB)       0.00      0.00      0.00       109\n 1. Cassava Brown Streak Disease (CBSD)       0.00      0.00      0.00       219\n          2. Cassava Green Mottle (CGM)       0.00      0.00      0.00       238\n        3. Cassava Mosaic Disease (CMD)       0.61      1.00      0.76      1316\n                             4. Healthy       0.00      0.00      0.00       258\n\n                               accuracy                           0.61      2140\n                              macro avg       0.12      0.20      0.15      2140\n                           weighted avg       0.38      0.61      0.47      2140\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val['label'].astype('int')","execution_count":106,"outputs":[{"output_type":"execute_result","execution_count":106,"data":{"text/plain":"0       2\n1       2\n2       3\n3       3\n4       3\n       ..\n2135    3\n2136    3\n2137    3\n2138    3\n2139    2\nName: label, Length: 2140, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\ndirec = \"../input/cassava-leaf-disease-classification/\"\ntest_direc = direc + \"test_images/\"\nsample_sub_csv = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n\nfor image in sample_sub_csv.image_id:\n    img = keras.preprocessing.image.load_img('../input/cassava-leaf-disease-classification/test_images/' + image)\n    img = keras.preprocessing.image.img_to_array(img)\n    img = keras.preprocessing.image.smart_resize(img, (IMG_SIZE, IMG_SIZE))\n    img = tf.reshape(img, (-1, IMG_SIZE, IMG_SIZE, 3))\n    prediction = RESNET_model.predict(img/255)\n    preds.append(np.argmax(prediction))\n\nfinal_submission = pd.DataFrame({'image_id': sample_sub_csv.image_id, 'label': preds})\nfinal_submission.to_csv('submission.csv', index=False) ","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}