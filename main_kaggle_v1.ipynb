{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pylab as plt\nimport glob\nimport os\nimport random\nimport keras\nfrom keras import backend as K\nfrom keras import layers\nfrom keras import metrics\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Dense, Dropout, Activation, Flatten, Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.models import Sequential, Model\nfrom keras.utils import plot_model\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nimport cv2\nfrom tqdm import tqdm\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.applications.inception_v3 import InceptionV3, preprocess_input\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split\nimport sklearn\nfrom collections import Counter\nfrom pandas import DataFrame\nimport gc\nimport tensorflow as tf\nfrom sklearn.utils import class_weight\nfrom sklearn.utils.class_weight import compute_class_weight","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv_path = \"../input/cassava-leaf-disease-classification/train.csv\"\nlabel_json_path = \"../input/cassava-leaf-disease-classification/label_num_to_disease_map.json\"\nimages_dir_path = \"../input/cassava-leaf-disease-classification/train_images\"\ntrain_csv = pd.read_csv(train_csv_path)\ntrain_csv['label'] = train_csv['label'].astype('string')\n\nx_train, x_val, y_train, y_val = train_test_split(train_csv['image_id'], train_csv['label'], test_size = 0.1, random_state = 27, stratify=train_csv['label'])\n\n#train df\ndf_train = pd.DataFrame(columns=['image_id','label'])\ndf_train['image_id'] = x_train\ndf_train['label'] = y_train\n\n#validation df\ndf_val = pd.DataFrame(columns=['image_id','label'])\ndf_val['image_id'] = x_val\ndf_val['label'] = y_val\n\ndf_train.reset_index(drop=True, inplace=True)\ndf_val.reset_index(drop=True, inplace=True)\n\nlabel_class = pd.read_json(label_json_path, orient='index')\nlabel_class = label_class.values.flatten().tolist()\nIMG_SIZE = 320\nBATCH_SIZE = 150\nEPOCHS = 15","execution_count":57,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=['0' '1' '2' '3' '4'], y=8644     3\n18281    0\n14735    0\n3906     1\n11276    3\n        ..\n1570     1\n20304    3\n16067    1\n18894    2\n13547    3\nName: label, Length: 19257, dtype: string as keyword args. From version 0.25 passing these as positional arguments will result in an error\n  FutureWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Label names :\")\nfor i, label in enumerate(label_class):\n    print(f\" {i}. {label}\")","execution_count":33,"outputs":[{"output_type":"stream","text":"Label names :\n 0. Cassava Bacterial Blight (CBB)\n 1. Cassava Brown Streak Disease (CBSD)\n 2. Cassava Green Mottle (CGM)\n 3. Cassava Mosaic Disease (CMD)\n 4. Healthy\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = ImageDataGenerator(\n                                rotation_range=270,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                brightness_range=[0.1,0.9],\n                                shear_range=25,\n                                zoom_range=0.3,\n                                channel_shift_range=0.1,\n                                horizontal_flip=True,\n                                vertical_flip=True,\n                                rescale=1/255,\n                                validation_split=0.2\n                               )\n                                    \n    \nvalid_gen = ImageDataGenerator(rescale=1/255,\n                               validation_split = 0.2\n                              )","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_gen.flow_from_dataframe(\n                            dataframe=df_train,\n                            directory = images_dir_path,\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            class_mode = \"categorical\",\n                            batch_size = BATCH_SIZE,\n                            shuffle = True,\n                            subset = \"training\"\n\n)\n\nvalid_generator = valid_gen.flow_from_dataframe(\n                            dataframe=df_val,\n                            directory = images_dir_path,\n                            x_col = \"image_id\",\n                            y_col = \"label\",\n                            target_size = (IMG_SIZE, IMG_SIZE),\n                            class_mode = \"categorical\",\n                            batch_size = BATCH_SIZE,\n                            shuffle = False,\n                            subset = \"validation\"\n)","execution_count":59,"outputs":[{"output_type":"stream","text":"Found 15406 validated image filenames belonging to 5 classes.\nFound 428 validated image filenames belonging to 5 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encode target variables\ndef encode_target_variable(y_train,y_val):\n\n    class_weights = compute_class_weight('balanced', np.unique(y_train), y_train)\n    d_class_weights = dict(enumerate(class_weights))\n    onehot_encoder = OneHotEncoder(sparse=False)\n    y_train = np.array(y_train)\n    y_val = np.array(y_val)\n    y_train = y_train.reshape(-1,1)\n    y_val = y_val.reshape(-1,1)\n    y_train_onehot = onehot_encoder.fit_transform(y_train)\n    y_val_onehot = onehot_encoder.fit_transform(y_val)\n    return y_train_onehot, y_val_onehot, d_class_weights","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_0(input_shape):\n    input_img = Input(shape=input_shape)  \n    x = Conv2D(16, (5, 5), activation='relu', padding='same')(input_img)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(16, (5, 5), activation='relu', padding='same')(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    x = Conv2D(16, (5, 5), activation='relu', padding='same')(x)\n    x = Dropout(0.3)(x)\n    y = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n    y = MaxPooling2D((2, 2), padding='same')(y)\n    y = Conv2D(16, (3, 3), activation='relu', padding='same')(y)\n    y = MaxPooling2D((2, 2), padding='same')(y)\n    y = Conv2D(16, (3, 3), activation='relu', padding='same')(y)\n    y = Dropout(0.4)(y)\n    z = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n    z = MaxPooling2D((2, 2), padding='same')(z)\n    z = Conv2D(16, (3, 3), activation='relu', padding='same')(z)\n    z = MaxPooling2D((2, 2), padding='same')(z)\n    z = Conv2D(16, (3, 3), activation='relu', padding='same')(z)\n\n    out = layers.concatenate([x, y, z])\n    out = layers.Flatten()(out)\n    out = Dense(16, activation='selu')(out)\n    out = Dense(5, activation='softmax')(out)\n    \n    model_f = Model(inputs=[input_img], outputs=[out])\n    model_f.summary()\n    return model_f","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_1(x_train,x_val,input_shape):\n    weights_path = '../input/weightsclimbers/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    resnet50 = ResNet50(weights = None ,include_top=False, input_shape=(IMG_SIZE_X, IMG_SIZE_Y,3))\n    resnet50.load_weights(weights_path, by_name=True)\n    resnet50.trainable = False # remove if you want to retrain resnet weights\n    # resnet50.summary()\n    transfer_model_1 = Sequential() \n    transfer_model_1.add(resnet50)\n    transfer_model_1.add(Flatten())\n    transfer_model_1.add(Dense(128, activation='relu'))\n    transfer_model_1.add(Dropout(0.2))\n    transfer_model_1.add(Dense(5, activation='softmax'))\n    transfer_model_1.summary()\n    x_train_new = x_train\n    x_val_new = x_val\n    x_train_new = keras.applications.resnet50.preprocess_input(x_train_new)\n    x_val_new = keras.applications.resnet50.preprocess_input(x_val_new)\n    return transfer_model_1, x_train_new, x_val_new","execution_count":62,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_2(x_train,x_val):\n    weights_path = '../input/weightsclimbers/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    vgg16 = VGG16(weights=None, include_top=False, input_shape=(IMG_SIZE_X, IMG_SIZE_Y, 3))\n    vgg16.load_weights(weights_path, by_name=True)\n    vgg16.trainable = False # remove if you want to retrain vgg16 weights\n    # vgg16.summary()\n    transfer_model_2 = Sequential()\n    transfer_model_2.add(vgg16)\n    transfer_model_2.add(Flatten())\n    transfer_model_2.add(Dense(128, activation='relu'))\n    transfer_model_2.add(Dropout(0.2))\n    transfer_model_2.add(Dense(5, activation='softmax'))\n    transfer_model_2.summary()\n    x_train_new = x_train\n    x_val_new = x_val\n    x_train_new = keras.applications.vgg16.preprocess_input(x_train_new)\n    x_val_new = keras.applications.vgg16.preprocess_input(x_val_new)\n    return transfer_model_2, x_train_new, x_val_new","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_3(x_train,x_val):\n    weights_path = '../input/weightsclimbers/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n    inceptionV3 = InceptionV3(weights=None, include_top=False, input_shape=(IMG_SIZE_X, IMG_SIZE_Y, 3))\n    inceptionV3.load_weights(weights_path, by_name=False)\n    inceptionV3.trainable = False # remove if you want to retrain rinceptionV3 weights\n    # inceptionV3.summary()\n    transfer_model_3 = Sequential()\n    transfer_model_3.add(inceptionV3)\n    transfer_model_3.add(Flatten())\n    transfer_model_3.add(Dense(128, activation='relu'))\n    transfer_model_3.add(Dropout(0.2))\n    transfer_model_3.add(Dense(5, activation='softmax'))\n    transfer_model_3.summary()\n    x_train_new = x_train\n    x_val_new = x_val\n    x_train_new = keras.applications.inception_v3.preprocess_input(x_train_new)\n    x_val_new = keras.applications.inception_v3.preprocess_input(x_val_new)\n    return transfer_model_3, x_train_new, x_val_new","execution_count":64,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, batch_size, epochs):\n    \n    batch_size = batch_size\n    epochs = epochs\n    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n              metrics=['categorical_accuracy',keras.metrics.AUC(),keras.metrics.Recall()])\n    \n    \n    model.fit_generator(train_generator, \n                    epochs=epochs,  # one forward/backward pass of training data\n                    steps_per_epoch=x_train.shape[0]//batch_size,  # number of images comprising of one epoch\n                    validation_data=valid_generator, # Or validation_data=valid_generator\n                    validation_steps=x_val.shape[0]//batch_size)\n    return model","execution_count":65,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"################## Main function ######################\n\n    \n#Baseline model\n\ninput_shape = [IMG_SIZE,IMG_SIZE,channels]\nbaseline_model = create_model_0(input_shape)\nbaseline_model = train_model(baseline_model, BATCH_SIZE, EPOCHS)\n\n\n# #Resnet50\n# x_train, x_val, y_train, y_val = data_preparation(training_data[0], training_data[1], new_h, new_w, channels)\n# y_train_onehot, y_val_onehot, class_weights = encode_target_variable(y_train,y_val)\n# del y_train, y_val\n# resnet50_model, x_train_new, x_val_new = create_model_1(x_train,x_val,input_shape)\n# del x_train,x_val\n# gc.collect()\n# resnet50_model = train_model(resnet50_model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot, class_weights)\n# #vgg16\n# x_train, x_val, y_train, y_val = data_preparation(training_data[2], training_data[3], new_h, new_w, channels)\n# y_train_onehot, y_val_onehot, class_weights = encode_target_variable(y_train,y_val)\n# del y_train, y_val\n# vgg16_model, x_train_new, x_val_new = create_model_2(x_train,x_val)\n# del x_train,x_val\n# gc.collect()\n# vgg16_model = train_model(vgg16_model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot, class_weights)\n# #InceptionV3\n# x_train, x_val, y_train, y_val = data_preparation(training_data[4], training_data[5], new_h,new_w, channels)\n# y_train_onehot, y_val_onehot, class_weights = encode_target_variable(y_train,y_val)\n# del y_train, y_val\n# inception_model, x_train_new, x_val_new = create_model_3(x_train,x_val)\n# del x_train,x_val\n# gc.collect()\n# inception_model = train_model(inception_model, batch_size, epochs, x_train_new, x_val_new, y_train_onehot, y_val_onehot, class_weights)","execution_count":null,"outputs":[{"output_type":"stream","text":"Model: \"functional_7\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_7 (InputLayer)            [(None, 320, 320, 3) 0                                            \n__________________________________________________________________________________________________\nconv2d_121 (Conv2D)             (None, 320, 320, 16) 1216        input_7[0][0]                    \n__________________________________________________________________________________________________\nconv2d_124 (Conv2D)             (None, 320, 320, 16) 448         input_7[0][0]                    \n__________________________________________________________________________________________________\nmax_pooling2d_22 (MaxPooling2D) (None, 160, 160, 16) 0           conv2d_121[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_24 (MaxPooling2D) (None, 160, 160, 16) 0           conv2d_124[0][0]                 \n__________________________________________________________________________________________________\nconv2d_127 (Conv2D)             (None, 320, 320, 16) 448         input_7[0][0]                    \n__________________________________________________________________________________________________\nconv2d_122 (Conv2D)             (None, 160, 160, 16) 6416        max_pooling2d_22[0][0]           \n__________________________________________________________________________________________________\nconv2d_125 (Conv2D)             (None, 160, 160, 16) 2320        max_pooling2d_24[0][0]           \n__________________________________________________________________________________________________\nmax_pooling2d_26 (MaxPooling2D) (None, 160, 160, 16) 0           conv2d_127[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_23 (MaxPooling2D) (None, 80, 80, 16)   0           conv2d_122[0][0]                 \n__________________________________________________________________________________________________\nmax_pooling2d_25 (MaxPooling2D) (None, 80, 80, 16)   0           conv2d_125[0][0]                 \n__________________________________________________________________________________________________\nconv2d_128 (Conv2D)             (None, 160, 160, 16) 2320        max_pooling2d_26[0][0]           \n__________________________________________________________________________________________________\nconv2d_123 (Conv2D)             (None, 80, 80, 16)   6416        max_pooling2d_23[0][0]           \n__________________________________________________________________________________________________\nconv2d_126 (Conv2D)             (None, 80, 80, 16)   2320        max_pooling2d_25[0][0]           \n__________________________________________________________________________________________________\nmax_pooling2d_27 (MaxPooling2D) (None, 80, 80, 16)   0           conv2d_128[0][0]                 \n__________________________________________________________________________________________________\ndropout_9 (Dropout)             (None, 80, 80, 16)   0           conv2d_123[0][0]                 \n__________________________________________________________________________________________________\ndropout_10 (Dropout)            (None, 80, 80, 16)   0           conv2d_126[0][0]                 \n__________________________________________________________________________________________________\nconv2d_129 (Conv2D)             (None, 80, 80, 16)   2320        max_pooling2d_27[0][0]           \n__________________________________________________________________________________________________\nconcatenate_5 (Concatenate)     (None, 80, 80, 48)   0           dropout_9[0][0]                  \n                                                                 dropout_10[0][0]                 \n                                                                 conv2d_129[0][0]                 \n__________________________________________________________________________________________________\nflatten_6 (Flatten)             (None, 307200)       0           concatenate_5[0][0]              \n__________________________________________________________________________________________________\ndense_12 (Dense)                (None, 16)           4915216     flatten_6[0][0]                  \n__________________________________________________________________________________________________\ndense_13 (Dense)                (None, 5)            85          dense_12[0][0]                   \n==================================================================================================\nTotal params: 4,939,525\nTrainable params: 4,939,525\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/15\n 61/128 [=============>................] - ETA: 5:34 - loss: 1.5157 - categorical_accuracy: 0.5848 - auc_6: 0.7593 - recall_6: 0.4352","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\ndirec = \"../input/cassava-leaf-disease-classification/\"\ntest_direc = direc + \"test_images/\"\nsample_sub_csv = pd.read_csv('../input/cassava-leaf-disease-classification/sample_submission.csv')\n\nfor image in sample_sub_csv.image_id:\n    img = keras.preprocessing.image.load_img('../input/cassava-leaf-disease-classification/test_images/' + image)\n    img = keras.preprocessing.image.img_to_array(img)\n    img = keras.preprocessing.image.smart_resize(img, (IMG_SIZE_X, IMG_SIZE_Y))\n    img = tf.reshape(img, (-1, IMG_SIZE_X, IMG_SIZE_Y, 3))\n    prediction = baseline_model.predict(img/255)\n    preds.append(np.argmax(prediction))\n\nfinal_submission = pd.DataFrame({'image_id': sample_sub_csv.image_id, 'label': preds})\nfinal_submission.to_csv('submission.csv', index=False) ","execution_count":31,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}